import pandas as pd
import numpy as np

class EnhancedFeatureEngineer:
    def __init__(self):
        pass

    def _ensure_datetime(self, df, col='æ—¥æœŸ'):
        if col in df.columns:
            df = df.copy()
            df[col] = pd.to_datetime(df[col])
            return df
        else:
            raise ValueError(f"åˆ— '{col}' ä¸å­˜åœ¨äº DataFrame ä¸­ã€‚")

    def create_temporal_features(self, dates_df):
        df = dates_df.copy().drop_duplicates().reset_index(drop=True)
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
        df['day_of_week'] = df['æ—¥æœŸ'].dt.dayofweek
        df['day_of_month'] = df['æ—¥æœŸ'].dt.day
        df['month'] = df['æ—¥æœŸ'].dt.month
        df['quarter'] = df['æ—¥æœŸ'].dt.quarter
        df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)
        df['is_month_start'] = (df['day_of_month'] <= 5).astype(int)
        df['is_month_end'] = (df['day_of_month'] >= 25).astype(int)
        return df

    def create_equipment_features(self, equipment_df, status_df):
        df = status_df.merge(
            equipment_df[['è®¾å¤‡ID', 'ç†è®ºé€Ÿåº¦(ç“¶/å¤©)', 'æ­£å¸¸é€Ÿåº¦(ç“¶/å¤©)', 'æ•ˆç‡', 'åŒºåŸŸID', 'å·¥åºç±»å‹']],
            on='è®¾å¤‡ID', how='left'
        )
        df['availability_ratio'] = df['è¿è¡Œæ—¶é•¿(å°æ—¶)'] / 16.0
        df['output_per_hour'] = df['å½“æ—¥äº§é‡(ç“¶)'] / df['è¿è¡Œæ—¶é•¿(å°æ—¶)'].replace(0, np.nan)
        df['capacity_utilization'] = df['å½“æ—¥äº§é‡(ç“¶)'] / df['ç†è®ºé€Ÿåº¦(ç“¶/å¤©)']
        df['efficiency_gap'] = df['æ•ˆç‡'] - (df['å½“æ—¥äº§é‡(ç“¶)'] / df['æ­£å¸¸é€Ÿåº¦(ç“¶/å¤©)'])
        df['is_downtime'] = (df['åœæœºæ—¶é•¿(å°æ—¶)'] > 0).astype(int)
        df = df.sort_values(['è®¾å¤‡ID', 'æ—¥æœŸ']).reset_index(drop=True)

        lag_cols = ['capacity_utilization', 'efficiency_gap', 'output_per_hour']
        for col in lag_cols:
            for lag in [1, 3]:
                df[f'{col}_lag{lag}'] = df.groupby('è®¾å¤‡ID')[col].shift(lag)
        for col in lag_cols:
            df[f'{col}_roll3_mean'] = df.groupby('è®¾å¤‡ID')[col].transform(lambda x: x.rolling(3, min_periods=1).mean())
            df[f'{col}_roll3_std'] = df.groupby('è®¾å¤‡ID')[col].transform(lambda x: x.rolling(3, min_periods=1).std())
        df['efficiency_trend_3d'] = df.groupby('è®¾å¤‡ID')['efficiency_gap'].transform(
            lambda x: x.diff().rolling(3, min_periods=1).mean()
        )
        return df

    def create_buffer_features(self, buffer_df):
        df = buffer_df.copy()
        df['buffer_turnover'] = df['å‡ºåº“æ•°é‡(ç›˜)'] / (df['æœŸåˆæ•°é‡(ç›˜)'] + 1)
        df['inventory_coverage'] = df['æœŸåˆæ•°é‡(ç›˜)'] / (df['å‡ºåº“æ•°é‡(ç›˜)'].replace(0, 1))
        df['safety_stock_ratio'] = df['æœŸåˆæ•°é‡(ç›˜)'] / (df['å®‰å…¨åº“å­˜(ç›˜)'] + 1e-6)
        df['near_overflow'] = (df['safety_stock_ratio'] > 0.9).astype(int)
        df['near_empty'] = (df['safety_stock_ratio'] < 0.1).astype(int)

        df = df.sort_values(['ç¼“å†²åŒºID', 'æ—¥æœŸ'])
        df['buffer_change'] = df.groupby('ç¼“å†²åŒºID')['æœŸåˆæ•°é‡(ç›˜)'].diff()
        df['buffer_depletion_rate'] = df.groupby('ç¼“å†²åŒºID')['buffer_change'].transform(
            lambda x: x.rolling(3, min_periods=1).mean()
        )
        return df

    def create_process_balance_features(self, production_df):
        proc_pivot = production_df.pivot_table(
            index='æ—¥æœŸ',
            columns='å·¥åºç±»å‹',
            values='æ€»äº§é‡(ç“¶)',
            aggfunc='sum'
        ).reset_index()
        for col in ['çŒè£…', 'ç­èŒ', 'åŒ…è£…']:
            if col not in proc_pivot.columns:
                proc_pivot[col] = 0
        proc_pivot['fill_to_ster_ratio'] = proc_pivot['ç­èŒ'] / (proc_pivot['çŒè£…'] + 1e-6)
        proc_pivot['ster_to_pack_ratio'] = proc_pivot['åŒ…è£…'] / (proc_pivot['ç­èŒ'] + 1e-6)
        proc_pivot['fill_to_pack_ratio'] = proc_pivot['åŒ…è£…'] / (proc_pivot['çŒè£…'] + 1e-6)
        proc_pivot['bottleneck_score_fill'] = proc_pivot['çŒè£…'] / (proc_pivot[['ç­èŒ', 'åŒ…è£…']].min(axis=1) + 1e-6)
        proc_pivot['bottleneck_score_ster'] = proc_pivot['ç­èŒ'] / (proc_pivot['åŒ…è£…'] + 1e-6)
        proc_pivot['is_bottleneck_fill'] = (proc_pivot['bottleneck_score_fill'] > 1.1).astype(int)
        proc_pivot['is_bottleneck_ster'] = (proc_pivot['bottleneck_score_ster'] > 1.1).astype(int)
        return proc_pivot

    def create_labels(self, status_df, buffer_feat, process_balance_df):
        labels = pd.DataFrame({'æ—¥æœŸ': pd.to_datetime(status_df['æ—¥æœŸ'].unique())})

        # åœæœºé¢„è­¦
        downtime_next = status_df.copy()
        downtime_next['next_downtime'] = downtime_next.groupby('è®¾å¤‡ID')['åœæœºæ—¶é•¿(å°æ—¶)'].shift(-1) > 0
        label_downtime = downtime_next.groupby('æ—¥æœŸ')['next_downtime'].any().reset_index()
        labels = labels.merge(label_downtime, on='æ—¥æœŸ', how='left')

        # ç¼“å†²åŒºçŸ­ç¼ºé¢„è­¦
        buffer_next = buffer_feat.copy()
        buffer_next['next_near_empty'] = buffer_next.groupby('ç¼“å†²åŒºID')['near_empty'].shift(-1)
        label_buffer = buffer_next.groupby('æ—¥æœŸ')['next_near_empty'].any().reset_index()
        labels = labels.merge(label_buffer, on='æ—¥æœŸ', how='left')

        # ç“¶é¢ˆæ ‡ç­¾
        labels = labels.merge(
            process_balance_df[['æ—¥æœŸ', 'is_bottleneck_fill', 'is_bottleneck_ster']],
            on='æ—¥æœŸ', how='left'
        )

        label_cols = ['next_downtime', 'next_near_empty', 'is_bottleneck_fill', 'is_bottleneck_ster']
        for col in label_cols:
            if col in labels.columns:
                labels[col] = labels[col].fillna(0).astype(int)
        return labels

    def aggregate_to_daily(self, equipment_features, buffer_features, process_features, labels):
        all_dates = pd.concat([
            equipment_features[['æ—¥æœŸ']],
            buffer_features[['æ—¥æœŸ']],
            process_features[['æ—¥æœŸ']],
            labels[['æ—¥æœŸ']]
        ]).drop_duplicates().reset_index(drop=True)
        feature_matrix = self.create_temporal_features(all_dates)

        # è®¾å¤‡èšåˆ
        equip_agg = equipment_features.groupby('æ—¥æœŸ').agg({
            'capacity_utilization': ['mean', 'std', 'max', 'min'],
            'efficiency_gap': ['mean', 'std', 'max'],
            'availability_ratio': ['mean', 'min'],
            'is_downtime': 'sum',
            'output_per_hour': 'mean',
            'efficiency_trend_3d': 'mean'
        }).round(6)
        equip_agg.columns = ['equip_' + '_'.join(col).strip() for col in equip_agg.columns]
        equip_agg = equip_agg.reset_index()

        # åŒºåŸŸèšåˆ
        area_agg = equipment_features.groupby(['æ—¥æœŸ', 'åŒºåŸŸID']).agg({
            'capacity_utilization': 'mean'
        }).unstack('åŒºåŸŸID')
        area_agg.columns = [f'area_{col[1]}_util' for col in area_agg.columns]
        area_agg = area_agg.reset_index()

        feature_matrix = feature_matrix.merge(equip_agg, on='æ—¥æœŸ', how='left')
        feature_matrix = feature_matrix.merge(area_agg, on='æ—¥æœŸ', how='left')

        # ç¼“å†²åŒºèšåˆï¼ˆæŒ‰æ—¥æœŸå¹³å‡ï¼‰
        buffer_daily = buffer_features.groupby('æ—¥æœŸ').agg({
            'buffer_turnover': 'mean',
            'inventory_coverage': 'mean',
            'safety_stock_ratio': 'mean',
            'near_overflow': 'max',
            'near_empty': 'max',
            'buffer_depletion_rate': 'mean'
        }).reset_index()
        feature_matrix = feature_matrix.merge(buffer_daily, on='æ—¥æœŸ', how='left')

        # å·¥åºå¹³è¡¡ç‰¹å¾ï¼ˆç›´æ¥åˆå¹¶ï¼‰
        feature_matrix = feature_matrix.merge(
            process_features[['æ—¥æœŸ', 'fill_to_pack_ratio', 'bottleneck_score_fill', 'bottleneck_score_ster']],
            on='æ—¥æœŸ', how='left'
        )

        # åˆå¹¶æ ‡ç­¾
        feature_matrix = feature_matrix.merge(labels, on='æ—¥æœŸ', how='left')

        # ğŸ”¥ æ–°å¢ï¼šå›å½’ç›®æ ‡ï¼ˆLSTM æ‰€éœ€ï¼‰
        feature_matrix['production_gap'] = feature_matrix['equip_capacity_utilization_mean'] - 0.85
        feature_matrix['filling_packaging_balance'] = feature_matrix['fill_to_pack_ratio']
        feature_matrix['bottleneck_severity'] = feature_matrix[['bottleneck_score_fill', 'bottleneck_score_ster']].max(axis=1)
        feature_matrix['buffer_risk_score'] = 1.0 - feature_matrix['safety_stock_ratio']

        # æ’åº & å¡«å……ç¼ºå¤±
        feature_matrix = feature_matrix.sort_values('æ—¥æœŸ').reset_index(drop=True)
        feature_matrix = feature_matrix.fillna(method='ffill').fillna(0)

        return feature_matrix

    def run_pipeline(self,
                    equipment_file='equipment_base.csv',
                    status_file='equipment_status_daily.csv',
                    buffer_file='buffer_inventory_daily.csv',
                    production_file='production_daily.csv'):
        print("ğŸ” æ­£åœ¨åŠ è½½æ•°æ®...")
        equip_df = pd.read_csv(equipment_file)
        status_df = self._ensure_datetime(pd.read_csv(status_file))
        buffer_df = self._ensure_datetime(pd.read_csv(buffer_file))
        prod_df = self._ensure_datetime(pd.read_csv(production_file))

        print("âš™ï¸ æ­£åœ¨æ„å»ºè®¾å¤‡ç‰¹å¾...")
        equip_feat = self.create_equipment_features(equip_df, status_df)

        print("ğŸ“¦ æ­£åœ¨æ„å»ºç¼“å†²åŒºç‰¹å¾...")
        buffer_feat = self.create_buffer_features(buffer_df)

        print("âš–ï¸ æ­£åœ¨æ„å»ºå·¥åºå¹³è¡¡ç‰¹å¾...")
        process_feat = self.create_process_balance_features(prod_df)

        print("ğŸ¯ æ­£åœ¨ç”Ÿæˆé¢„æµ‹æ ‡ç­¾...")
        labels = self.create_labels(status_df, buffer_feat, process_feat)

        print("ğŸ§© æ­£åœ¨èšåˆç‰¹å¾çŸ©é˜µ...")
        final_features = self.aggregate_to_daily(equip_feat, buffer_feat, process_feat, labels)

        print(f"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆï¼ç‰¹å¾ç»´åº¦: {final_features.shape}")
        return final_features


if __name__ == "__main__":
    engineer = EnhancedFeatureEngineer()
    features = engineer.run_pipeline()
    features.to_csv('enhanced_production_features.csv', index=False, encoding='utf-8-sig')
    print("\nğŸ’¾ ç‰¹å¾çŸ©é˜µå·²ä¿å­˜è‡³: enhanced_production_features.csv")