# inference_module.py
import os
import pandas as pd
import numpy as np
import joblib
from tensorflow.keras.models import load_model
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# ==============================
# 1. ç‰¹å¾å·¥ç¨‹å‡½æ•°ï¼ˆç²¾ç¡®åŒ¹é…åŸå§‹æ•°æ®ï¼‰
# ==============================
def build_features_from_raw(
    production_file: str,
    status_file: str,
    efficiency_file: str,
    base_file: str,
    buffer_file: str,
    target_date: str
) -> pd.DataFrame:
    """
    ä»5ä¸ªåŸå§‹CSVæ–‡ä»¶æ„å»ºä¸ enhanced_production_features.csv ä¸€è‡´çš„ç‰¹å¾
    :param target_date: é¢„æµ‹ç›®æ ‡æ—¥æœŸï¼ˆå­—ç¬¦ä¸²ï¼‰
    :return: å•è¡Œ DataFrameï¼Œå«30ä¸ªç‰¹å¾ + æ—¥æœŸ
    """
    target_date = pd.to_datetime(target_date)
    feat_date = target_date - timedelta(days=1)  # ä½¿ç”¨å‰ä¸€å¤©æ•°æ®

    # --- åŠ è½½æ•°æ® ---
    prod_df = pd.read_csv(production_file, parse_dates=['æ—¥æœŸ'])
    status_df = pd.read_csv(status_file, parse_dates=['æ—¥æœŸ'])
    eff_df = pd.read_csv(efficiency_file, parse_dates=['æ—¥æœŸ'])
    base_df = pd.read_csv(base_file)
    buffer_df = pd.read_csv(buffer_file, parse_dates=['æ—¥æœŸ'])

    # --- 1. æ—¶é—´ç‰¹å¾ ---
    features = {
        'æ—¥æœŸ': target_date,
        'day_of_week': feat_date.dayofweek,
        'day_of_month': feat_date.day,
        'month': feat_date.month,
        'quarter': (feat_date.month - 1) // 3 + 1,
        'is_weekend': int(feat_date.dayofweek >= 5),
        'is_month_start': int(feat_date.day == 1),
        'is_month_end': int(feat_date.is_month_end),  # âœ… ä¿®æ­£ï¼šå±æ€§ï¼Œæ— æ‹¬å·
    }

    # --- 2. åˆå¹¶è®¾å¤‡åŸºç¡€ä¿¡æ¯ ---
    status_df = status_df.merge(base_df, on='è®¾å¤‡ID', how='left')
    eff_df = eff_df.merge(base_df, on='è®¾å¤‡ID', how='left')

    # --- 3. è®¾å¤‡çº§ç‰¹å¾è®¡ç®— ---
    status_day = status_df[status_df['æ—¥æœŸ'] == feat_date].copy()
    eff_day = eff_df[eff_df['æ—¥æœŸ'] == feat_date].copy()

    if not eff_day.empty:
        # äº§èƒ½åˆ©ç”¨ç‡ï¼ˆå®é™… / ç†è®ºï¼‰
        eff_day['äº§èƒ½åˆ©ç”¨ç‡'] = np.where(
            eff_day['ç†è®ºäº§èƒ½(ç“¶)'] > 0,
            eff_day['å®é™…äº§èƒ½(ç“¶)'] / eff_day['ç†è®ºäº§èƒ½(ç“¶)'],
            0.0
        )
        # è¿è¡Œæ•ˆç‡ï¼ˆå·²å­˜åœ¨ï¼‰
        eff_day['è¿è¡Œæ•ˆç‡'] = eff_day['è¿è¡Œæ•ˆç‡'].fillna(0.0)
        # æ•ˆç‡ gap = 1 - è¿è¡Œæ•ˆç‡
        eff_day['æ•ˆç‡_gap'] = 1.0 - eff_day['è¿è¡Œæ•ˆç‡']
        # å¯ç”¨ç‡ï¼ˆæ¥è‡ªåŸºç¡€è¡¨ï¼‰
        eff_day['å¯ç”¨ç‡'] = eff_day['å¯ç”¨ç‡'].fillna(0.9)

        util_vals = eff_day['äº§èƒ½åˆ©ç”¨ç‡'].values
        gap_vals = eff_day['æ•ˆç‡_gap'].values
        avail_vals = eff_day['å¯ç”¨ç‡'].values

        features.update({
            'equip_capacity_utilization_mean': float(np.mean(util_vals)),
            'equip_capacity_utilization_std': float(np.std(util_vals)) if len(util_vals) > 1 else 0.0,
            'equip_capacity_utilization_max': float(np.max(util_vals)),
            'equip_capacity_utilization_min': float(np.min(util_vals)),
            'equip_efficiency_gap_mean': float(np.mean(gap_vals)),
            'equip_efficiency_gap_std': float(np.std(gap_vals)) if len(gap_vals) > 1 else 0.0,
            'equip_efficiency_gap_max': float(np.max(gap_vals)),
            'equip_availability_ratio_mean': float(np.mean(avail_vals)),
            'equip_availability_ratio_min': float(np.min(avail_vals)),
            'equip_is_downtime_sum': int((eff_day['æ•…éšœæ¬¡æ•°'] > 0).sum()),
            'equip_output_per_hour_mean': float(eff_day['å®é™…äº§èƒ½(ç“¶)'].sum() / 24.0),
        })

        # åŒºåŸŸåˆ©ç”¨ç‡
        area_util = eff_day.groupby('åŒºåŸŸID')['äº§èƒ½åˆ©ç”¨ç‡'].mean()
        features['area_AREA_A_util'] = float(area_util.get('AREA_A', 0.0))
        features['area_AREA_B_util'] = float(area_util.get('AREA_B', 0.0))

        # ğŸ”§ ä¿®æ­£ï¼šçŒè£… vs åŒ…è£…äº§é‡ï¼ˆå®‰å…¨è®¡ç®— ratioï¼‰
        prod_day = prod_df[prod_df['æ—¥æœŸ'] == feat_date].copy()
        filler_prod = prod_day[prod_day['å·¥åºç±»å‹'] == 'çŒè£…']['æ€»äº§é‡(ç“¶)'].sum()
        packer_prod = prod_day[prod_day['å·¥åºç±»å‹'] == 'åŒ…è£…']['æ€»äº§é‡(ç“¶)'].sum()

        # å®‰å…¨è®¡ç®— fill_to_pack_ratio
        if packer_prod <= 0:
            fill_to_pack_ratio = 1.0  # é»˜è®¤å¹³è¡¡
        elif filler_prod <= 0:
            fill_to_pack_ratio = 0.0
        else:
            fill_to_pack_ratio = filler_prod / packer_prod
            # é™åˆ¶åˆç†èŒƒå›´ï¼Œé˜²æ­¢æç«¯å€¼å½±å“æ¨¡å‹
            fill_to_pack_ratio = max(0.0, min(fill_to_pack_ratio, 10.0))

        features['fill_to_pack_ratio'] = float(fill_to_pack_ratio)

        # ç“¶é¢ˆåˆ†æ•°ï¼ˆç®€åŒ–ï¼‰
        filler_gap = eff_day[eff_day['å·¥åºç±»å‹'] == 'çŒè£…']['æ•ˆç‡_gap'].mean()
        ster_gap = eff_day[eff_day['å·¥åºç±»å‹'] == 'ç­èŒ']['æ•ˆç‡_gap'].mean()
        features['bottleneck_score_fill'] = float(filler_gap) if not pd.isna(filler_gap) else 0.0
        features['bottleneck_score_ster'] = float(ster_gap) if not pd.isna(ster_gap) else 0.0

    else:
        for k in ['equip_capacity_utilization_mean', 'equip_efficiency_gap_mean',
                  'area_AREA_A_util', 'area_AREA_B_util', 'fill_to_pack_ratio']:
            features[k] = 0.0
        features.update({
            'equip_capacity_utilization_std': 0.0,
            'equip_capacity_utilization_max': 0.0,
            'equip_capacity_utilization_min': 0.0,
            'equip_efficiency_gap_std': 0.0,
            'equip_efficiency_gap_max': 0.0,
            'equip_availability_ratio_mean': 0.9,
            'equip_availability_ratio_min': 0.9,
            'equip_is_downtime_sum': 0,
            'equip_output_per_hour_mean': 0.0,
            'bottleneck_score_fill': 0.0,
            'bottleneck_score_ster': 0.0,
        })

    # --- 4. ç¼“å†²åŒºç‰¹å¾ ---
    buffer_day = buffer_df[buffer_df['æ—¥æœŸ'] == feat_date].copy()
    if not buffer_day.empty:
        buffer_day['å®‰å…¨åº“å­˜'] = buffer_day['å®‰å…¨åº“å­˜(ç›˜)']
        buffer_day['æœŸæœ«åº“å­˜'] = buffer_day['æœŸæœ«æ•°é‡(ç›˜)']
        buffer_day['å‡ºåº“é‡'] = buffer_day['å‡ºåº“æ•°é‡(ç›˜)']
        buffer_day['æœŸåˆåº“å­˜'] = buffer_day['æœŸåˆæ•°é‡(ç›˜)']

        total_out = buffer_day['å‡ºåº“é‡'].sum()
        total_begin = buffer_day['æœŸåˆåº“å­˜'].sum()
        total_end = buffer_day['æœŸæœ«åº“å­˜'].sum()
        total_safety = buffer_day['å®‰å…¨åº“å­˜'].sum()

        features['buffer_turnover'] = float(total_out / total_begin) if total_begin > 0 else 0.0
        features['inventory_coverage'] = float(total_end / (total_out / 24)) if total_out > 0 else 0.0
        features['safety_stock_ratio'] = float(total_end / total_safety) if total_safety > 0 else 1.0

        near_empty = (buffer_day['æœŸæœ«åº“å­˜'] < 0.2 * buffer_day['å®‰å…¨åº“å­˜']).any()
        near_overflow = (buffer_day['æœŸæœ«åº“å­˜'] > 1.5 * buffer_day['å®‰å…¨åº“å­˜']).any()
        features['near_empty'] = int(near_empty)
        features['near_overflow'] = int(near_overflow)
        features['buffer_depletion_rate'] = float((total_begin - total_end) / total_begin) if total_begin > 0 else 0.0
    else:
        for k in ['buffer_turnover', 'inventory_coverage', 'safety_stock_ratio',
                  'near_overflow', 'near_empty', 'buffer_depletion_rate']:
            features[k] = 0.0

    # --- 5. æ•ˆç‡è¶‹åŠ¿ï¼ˆè¿‡å»3å¤©ï¼‰---
    try:
        dates_3d = [feat_date - timedelta(days=i) for i in range(3)]
        eff_3d = eff_df[eff_df['æ—¥æœŸ'].isin(dates_3d)].copy()
        if len(eff_3d) >= 1:
            eff_3d['äº§èƒ½åˆ©ç”¨ç‡'] = np.where(
                eff_3d['ç†è®ºäº§èƒ½(ç“¶)'] > 0,
                eff_3d['å®é™…äº§èƒ½(ç“¶)'] / eff_3d['ç†è®ºäº§èƒ½(ç“¶)'],
                0.0
            )
            trend = eff_3d.groupby('æ—¥æœŸ')['äº§èƒ½åˆ©ç”¨ç‡'].mean().values
            if len(trend) >= 2:
                slope = np.polyfit(np.arange(len(trend)), trend, 1)[0]
                features['equip_efficiency_trend_3d_mean'] = float(slope)
            else:
                features['equip_efficiency_trend_3d_mean'] = 0.0
        else:
            features['equip_efficiency_trend_3d_mean'] = 0.0
    except Exception:
        features['equip_efficiency_trend_3d_mean'] = 0.0

    # --- 6. è¡¥å…¨æ‰€æœ‰30ä¸ªç‰¹å¾ ---
    expected_features = [
        'day_of_week', 'day_of_month', 'month', 'quarter', 'is_weekend',
        'is_month_start', 'is_month_end',
        'equip_capacity_utilization_mean', 'equip_capacity_utilization_std',
        'equip_capacity_utilization_max', 'equip_capacity_utilization_min',
        'equip_efficiency_gap_mean', 'equip_efficiency_gap_std', 'equip_efficiency_gap_max',
        'equip_availability_ratio_mean', 'equip_availability_ratio_min',
        'equip_is_downtime_sum', 'equip_output_per_hour_mean',
        'equip_efficiency_trend_3d_mean',
        'area_AREA_A_util', 'area_AREA_B_util',
        'buffer_turnover', 'inventory_coverage', 'safety_stock_ratio',
        'near_overflow', 'near_empty', 'buffer_depletion_rate',
        'fill_to_pack_ratio', 'bottleneck_score_fill', 'bottleneck_score_ster'
    ]
    for f in expected_features:
        if f not in features:
            features[f] = 0.0

    return pd.DataFrame([features])


# ==============================
# 2. æ¨ç†ä¸»å‡½æ•°ï¼ˆæ”¯æŒ XGBoost + LSTMï¼‰
# ==============================
def run_inference(
    production_file: str = 'production_daily.csv',
    status_file: str = 'equipment_status_daily.csv',
    efficiency_file: str = 'equipment_efficiency_daily.csv',
    base_file: str = 'equipment_base.csv',
    buffer_file: str = 'buffer_inventory_daily.csv',
    target_date: str = None
) -> dict:
    """
    ç«¯åˆ°ç«¯æ¨ç†ï¼šåŸå§‹æ•°æ® â†’ ç‰¹å¾ â†’ XGBoost + LSTM â†’ èåˆé¢„æµ‹
    """
    if target_date is None:
        target_date = (datetime.today() + timedelta(days=1)).strftime('%Y-%m-%d')

    # æ„å»ºç‰¹å¾
    features_df = build_features_from_raw(
        production_file, status_file, efficiency_file, base_file, buffer_file, target_date
    )

    FEATURE_COLS = [
        'day_of_week', 'day_of_month', 'month', 'quarter', 'is_weekend',
        'is_month_start', 'is_month_end',
        'equip_capacity_utilization_mean', 'equip_capacity_utilization_std',
        'equip_capacity_utilization_max', 'equip_capacity_utilization_min',
        'equip_efficiency_gap_mean', 'equip_efficiency_gap_std', 'equip_efficiency_gap_max',
        'equip_availability_ratio_mean', 'equip_availability_ratio_min',
        'equip_is_downtime_sum', 'equip_output_per_hour_mean',
        'equip_efficiency_trend_3d_mean',
        'area_AREA_A_util', 'area_AREA_B_util',
        'buffer_turnover', 'inventory_coverage', 'safety_stock_ratio',
        'near_overflow', 'near_empty', 'buffer_depletion_rate',
        'fill_to_pack_ratio', 'bottleneck_score_fill', 'bottleneck_score_ster'
    ]

    X = features_df[FEATURE_COLS].values.astype(np.float32)

    # --- 1. XGBoost é¢„æµ‹ ---
    xgb_model = joblib.load('xgb_multioutput_model.pkl')
    pred_xgb = xgb_model.predict(X)[0]

    # --- 2. LSTM é¢„æµ‹ï¼ˆéœ€è¿‡å»7å¤©å†å²ï¼‰---
    try:
        # è·å–æœ€è¿‘7å¤©ç‰¹å¾ï¼ˆç”¨äºLSTMï¼‰
        last_7_days = [pd.to_datetime(target_date) - timedelta(days=i) for i in range(7)]
        lstm_features = []
        for d in last_7_days:
            df = build_features_from_raw(
                production_file, status_file, efficiency_file, base_file, buffer_file, d.strftime('%Y-%m-%d')
            )
            lstm_features.append(df[FEATURE_COLS].values.flatten())
        X_lstm = np.array(lstm_features).reshape(1, 7, -1)

        # åŠ è½½ LSTM æ¨¡å‹å’Œæ ‡å‡†åŒ–å™¨
        scaler_X = joblib.load('lstm_scaler_X.pkl')
        scaler_y = joblib.load('lstm_scaler_y.pkl')
        model = load_model('lstm_multioutput_model.keras')

        X_lstm_scaled = scaler_X.transform(X_lstm.reshape(-1, X_lstm.shape[-1])).reshape(X_lstm.shape)
        pred_lstm_scaled = model.predict(X_lstm_scaled, verbose=0)
        pred_lstm = scaler_y.inverse_transform(pred_lstm_scaled)[0]

        # --- 3. èåˆç­–ç•¥ï¼šåŠ æƒå¹³å‡ ---
        final_pred = 0.7 * pred_xgb + 0.3 * pred_lstm  # XGBoost ä¸»å¯¼ï¼ŒLSTM æä¾›è¶‹åŠ¿
    except Exception as e:
        print(f"LSTM é¢„æµ‹å¤±è´¥ï¼Œä½¿ç”¨ XGBoost: {e}")
        final_pred = pred_xgb

    return {
        'date': target_date,
        'predictions': {
            'production_gap': float(final_pred[0]),
            'filling_packaging_balance': float(final_pred[1]),
            'bottleneck_severity': float(final_pred[2]),
            'buffer_risk_score': float(final_pred[3])
        },
        'model_used': 'fusion' if 'final_pred' in locals() and np.array_equal(final_pred, 0.7*pred_xgb + 0.3*pred_lstm) else 'xgboost'
    }


# ==============================
# 3. æµ‹è¯•
# ==============================
if __name__ == "__main__":
    try:
        result = run_inference(target_date='2025-10-22')
        print("âœ… æ¨ç†æˆåŠŸ!")
        print(f"é¢„æµ‹æ—¥æœŸ: {result['date']}")
        for k, v in result['predictions'].items():
            print(f"{k}: {v:.4f}")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()